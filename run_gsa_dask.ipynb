{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create bw project and set it to current "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Geothermal'  \n",
    "bw.projects.set_current(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 2 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.6 cutoff"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import biosphere and ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biosphere database already present!!! No setup is needed\n"
     ]
    }
   ],
   "source": [
    "bw.bw2setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoinvent 3.6 cutoff database already present!!! No import is needed\n"
     ]
    }
   ],
   "source": [
    "ei_name = \"ecoinvent 3.6 cutoff\"    \n",
    "# ei_path = \"/psi/home/kim_a/LCA files/ecoinvent 3.5 cutoff/datasets\"\n",
    "ei_path = \"/Users/akim/Documents/LCA files/ecoinvent 3.6 cutoff/datasets\"\n",
    "if ei_name in bw.databases:\n",
    "    print(ei_name + \" database already present!!! No import is needed\")\n",
    "else:\n",
    "    ei = bw.SingleOutputEcospold2Importer(ei_path, ei_name)\n",
    "    ei.apply_strategies()\n",
    "    ei.statistics()\n",
    "    ei.write_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import `geothermal energy` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 2 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.6 cutoff"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose which ecoinvent version should be linked to geothermal: \n",
      "ecoinvent 3.6 cutoff\n",
      "Extracted 1 worksheets in 0.08 seconds\n",
      "Applying strategy: csv_restore_tuples\n",
      "Applying strategy: csv_restore_booleans\n",
      "Applying strategy: csv_numerize\n",
      "Applying strategy: csv_drop_unknown\n",
      "Applying strategy: csv_add_missing_exchanges_section\n",
      "Applying strategy: normalize_units\n",
      "Applying strategy: normalize_biosphere_categories\n",
      "Applying strategy: normalize_biosphere_names\n",
      "Applying strategy: strip_biosphere_exc_locations\n",
      "Applying strategy: set_code_by_activity_hash\n",
      "Applying strategy: link_iterable_by_fields\n",
      "Applying strategy: assign_only_product_as_production\n",
      "Applying strategy: link_technosphere_by_activity_hash\n",
      "Applying strategy: drop_falsey_uncertainty_fields_but_keep_zeros\n",
      "Applying strategy: convert_uncertainty_types_to_integers\n",
      "Applying strategy: convert_activity_parameters_to_list\n",
      "Applied 16 strategies in 0.17 seconds\n",
      "Applying strategy: link_iterable_by_fields\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying strategy: link_iterable_by_fields\n",
      "12 datasets\n",
      "124 exchanges\n",
      "0 unlinked exchanges\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [############] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 02/09/2020 23:16:19\n",
      "  Finished: 02/09/2020 23:16:19\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 119.10\n",
      "  Memory %: 1.45\n",
      "Created database: geothermal energy\n"
     ]
    }
   ],
   "source": [
    "%run Import_and_Replace.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start DASK Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_comp = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option_comp == \"merlin\":\n",
    "\n",
    "    from dask_jobqueue import SLURMCluster\n",
    "    \n",
    "    cluster = SLURMCluster(cores     = 8, \n",
    "                           memory    ='4GB', \n",
    "                           walltime  = '06:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = '/data/user/kim_a',\n",
    "                           log_directory   = '/data/user/kim_a',\n",
    "                           job_extra=\"--exclusive\") \n",
    "    \n",
    "elif option_comp == \"local\":\n",
    "    \n",
    "    from dask.distributed import LocalCluster\n",
    "    \n",
    "    cluster = LocalCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 10\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:59421</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>10</li>\n",
       "  <li><b>Cores: </b>30</li>\n",
       "  <li><b>Memory: </b>42.95 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:59421' processes=10 threads=30, memory=42.95 GB>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import brightway2 as bw\n",
    "from copy import copy\n",
    "\n",
    "from utils.gsa_lca_dask import *\n",
    "from setup_files_gsa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose option: EGE or CGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'cge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose number of Monte Carlo runs for one total index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create long task for each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices):\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for sample in X_chunk:\n",
    "        score = gsa_in_lca.model(sample, method_matrices)\n",
    "        scores.append(score)\n",
    "        i += 1\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_per_worker(project, N, option, n_workers, i_chunk, path_files):\n",
    "\n",
    "    # 1. setup geothermal project\n",
    "    demand, methods, gt_model, parameters = setup_gt_project(project, option)\n",
    "\n",
    "    # 4. generate characterization matrices for all methods\n",
    "    lca = bw.LCA(demand, methods[0])\n",
    "    lca.lci(factorize=True)\n",
    "    lca.lcia()\n",
    "    lca.build_demand_array()\n",
    "    method_matrices = gen_cf_matrices(lca, methods)\n",
    "\n",
    "    # 5. gsa in lca model\n",
    "#     gsa_in_lca = GSAinLCA(lca, parameters, gt_model, options = ['geothermal energy'], project = project)\n",
    "    gsa_in_lca = GSAinLCA(lca, parameters, gt_model, project = project)\n",
    "\n",
    "    # 2. setup GSA project in the SALib format\n",
    "    num_vars = len(gsa_in_lca.parameters_array) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['tech_params_where']) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['bio_params_where'])\n",
    "\n",
    "    problem, calc_second_order = setup_gsa(num_vars)\n",
    "\n",
    "    # 3. generate all samples, choose correct chunk for the current worker based on index i_chunk\n",
    "    X = saltelli.sample(problem, N, calc_second_order=calc_second_order)\n",
    "#     np.random.seed(10)\n",
    "#     n_runs = N*(num_vars+2)\n",
    "#     X = np.random.random([n_runs, num_vars])\n",
    "\n",
    "    # Extract part of the sample for the current worker\n",
    "    chunk_size = X.shape[0]//n_workers\n",
    "    start = i_chunk*chunk_size\n",
    "    if i_chunk != n_workers-1:\n",
    "        end = (i_chunk+1)*chunk_size\n",
    "    else:\n",
    "        end = X.shape[0] \n",
    "    X_chunk = X[start:end, :]\n",
    "    del X\n",
    "\n",
    "    # 6. compute scores for all methods for X_chunk  \n",
    "    scores_for_methods = model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices)\n",
    "    \n",
    "    # 7. Save results\n",
    "    filepath = os.path.join(path_files, 'scores_' + str(start) + '_' + str(end-1) + '.pkl')\n",
    "    with open(filepath, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores_for_methods, fp)\n",
    "\n",
    "    return scores_for_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i_chunk = 0\n",
    "# scores_for_methods = task_per_worker(project, N, option, n_workers, i_chunk, path_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for saving results\n",
    "path = \"generated_files/write_files\"\n",
    "path_files = os.path.join(path, option + '_N' + str(N))\n",
    "if not os.path.exists(path_files):\n",
    "    os.makedirs(path_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_per_worker = dask.delayed(task_per_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals = []\n",
    "for i in range(n_workers):\n",
    "    model_eval = task_per_worker(project, N, option, n_workers, i, path_files)\n",
    "    model_evals.append(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 18s, sys: 2min 4s, total: 15min 23s\n",
      "Wall time: 3h 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_intermediate = dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing of model outputs Y and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_intermediate = np.array(Y_intermediate).squeeze()\n",
    "Y_all_methods = np.vstack(Y_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500, 16)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all_methods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(path_files, 'all_scores.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(Y_all_methods, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute sobol indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import numpy as np\n",
    "from SALib.analyze import sobol\n",
    "import pickle, json, os\n",
    "\n",
    "from setup_files_gsa import *\n",
    "from utils.gsa_lca_dask import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'cge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option == 'cge':\n",
    "    path = 'generated_files/write_files/cge_N500'\n",
    "elif option == 'ege':\n",
    "    path = 'generated_files/write_files/ege_N500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_lcia_results(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500, 16)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Geothermal'\n",
    "\n",
    "demand, methods, gt_model, parameters = setup_gt_project(project, option)\n",
    "\n",
    "lca = bw.LCA(demand, methods[0])\n",
    "lca.lci()\n",
    "lca.lcia()\n",
    "lca.build_demand_array()\n",
    "# gsa_in_lca = GSAinLCA(lca, parameters, gt_model, project = project, options=['geothermal energy'])\n",
    "gsa_in_lca = GSAinLCA(lca, parameters, gt_model, project = project)\n",
    "\n",
    "\n",
    "num_vars = len(gsa_in_lca.parameters_array) \\\n",
    "         + len(gsa_in_lca.uncertain_exchanges_dict['tech_params_where']) \\\n",
    "         + len(gsa_in_lca.uncertain_exchanges_dict['bio_params_where'])\n",
    "problem, calc_second_order = setup_gsa(num_vars)\n",
    "\n",
    "sa_dict = {}\n",
    "i = 0\n",
    "sa_dict['parameters'] = gsa_in_lca.parameters_array['name'].tolist()\n",
    "for Y in scores.transpose():\n",
    "    method_name = methods[i][-1]\n",
    "    dict_ = sobol.analyze(problem, Y, print_to_console=False, calc_second_order=calc_second_order)\n",
    "    for k,v in dict_.items():\n",
    "        dict_[k] = v.tolist()\n",
    "    sa_dict[method_name] = dict_\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Sobol indices\n",
    "path_sob = os.path.join(path, 'sobol_indices' + '.json')\n",
    "with open(path_sob, 'w') as f:\n",
    "    json.dump(sa_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA indices convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import numpy as np\n",
    "from SALib.analyze import sobol\n",
    "import pickle, json, os\n",
    "\n",
    "from setup_files_gsa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO --> choose option and for which parameter to plot SA convergence which_input = 12\n",
    "option = 'cge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option == 'cge':\n",
    "    path = 'generated_files/write_files/cge_N200'\n",
    "elif option == 'ege':\n",
    "    path = 'generated_files/write_files/ege_N200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sob = os.path.join(path, 'sobol_indices' + '.json')\n",
    "with open(path_sob, 'r') as f:\n",
    "    sa_dict = json.load(f)\n",
    "    \n",
    "inputs = sa_dict['parameters']\n",
    "D = len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob, cso = setup_gsa(D)\n",
    "\n",
    "project = 'Geothermal'\n",
    "_, methods, _, _ = setup_gt_project(project, option)\n",
    "n_methods = len(methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot error convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import colorlover as cl\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cl.scales['3']['qual']['Dark2']\n",
    "HTML(cl.to_html( colors ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_lcia_results(path)\n",
    "\n",
    "N_start = 5\n",
    "N_end = 200\n",
    "N_step = 5\n",
    "\n",
    "Ns = np.arange(N_start, N_end, N_step)\n",
    "Ns = Ns[:-1]\n",
    "first_d = np.zeros([Ns.shape[0], n_methods, len(inputs)])\n",
    "total_d = np.zeros([Ns.shape[0], n_methods, len(inputs)])\n",
    "\n",
    "i = 0\n",
    "for m, method in enumerate(methods):\n",
    "    i = 0\n",
    "    for n in Ns:\n",
    "        num_runs = n * (D+2)\n",
    "        scores_n = scores[:num_runs, m]\n",
    "        sa_dict = sobol.analyze(prob, scores_n, calc_second_order=cso)\n",
    "        first = sa_dict['S1']\n",
    "        total = sa_dict['ST']\n",
    "        first_d[i, m, :] = first\n",
    "        total_d[i, m, :] = total\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all methods for one parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO --> for which parameter to plot SA convergence \n",
    "which_input = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_names = [m[-1] for m in methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 2\n",
    "\n",
    "rows = int(np.ceil(len(methods)/cols))\n",
    "\n",
    "fig = make_subplots(rows=rows, \n",
    "                    cols=cols, \n",
    "                    start_cell=\"top-left\",\n",
    "                    subplot_titles=methods_names\n",
    "                   )\n",
    "\n",
    "showleg = True\n",
    "for m, method in enumerate(methods):\n",
    "    fig.add_trace(go.Scatter(x=Ns, \n",
    "                             y=first_d[:, m, which_input ],\n",
    "                             mode='lines+markers',\n",
    "                             line=go.scatter.Line(color=colors[0]),\n",
    "                             name = 'First index',\n",
    "                             showlegend = showleg, \n",
    "                             ),\n",
    "                  row=m//cols+1, \n",
    "                  col=m%cols+1, \n",
    "                  secondary_y=False,\n",
    "                  )\n",
    "     \n",
    "    fig.add_trace(go.Scatter(x=Ns, \n",
    "                             y=total_d[:, m, which_input],\n",
    "                             mode='lines+markers',\n",
    "                             line=go.scatter.Line(color=colors[2]),\n",
    "                             name = 'Total index',\n",
    "                             showlegend = showleg),\n",
    "                  row=m//cols+1, \n",
    "                  col=m%cols+1, \n",
    "                  secondary_y=False)\n",
    "\n",
    "    showleg = False\n",
    "    \n",
    "    \n",
    "fig.update_layout(width=990,\n",
    "                  height = 1100, \n",
    "                  legend_orientation=\"h\",\n",
    "                  legend=dict(x=0.67, y=1.1, font_size=16),\n",
    "                  title = inputs[which_input].replace('_',' ').capitalize(),\n",
    "                 )\n",
    "\n",
    "max_y = max(max(first_d[:, :, which_input].flatten()), max(total_d[:, :, which_input].flatten()))\n",
    "min_y = min(min(first_d[:, :, which_input].flatten()), min(total_d[:, :, which_input].flatten()))\n",
    "\n",
    "# fig.update_yaxes(range=[min_y-0.5, max_y+0.5])\n",
    "fig.update_yaxes(range=[-0.5,0.3])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for all parameters for one method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_method = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_names = [inp.replace('_', ' ') for inp in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 2\n",
    "rows = int(np.ceil(len(inputs)/cols))\n",
    "\n",
    "fig = make_subplots(rows=rows, \n",
    "                    cols=cols, \n",
    "                    start_cell=\"top-left\",\n",
    "                    subplot_titles=inputs_names\n",
    "                   )\n",
    "\n",
    "showleg = True\n",
    "for i, inp in enumerate(inputs):\n",
    "    fig.add_trace(go.Scatter(x=Ns, \n",
    "                             y=first_d[:, which_method, i],\n",
    "                             mode='lines+markers',\n",
    "                             line=go.scatter.Line(color=colors[0]),\n",
    "                             name = 'First index',\n",
    "                             showlegend = showleg, \n",
    "                             ),\n",
    "                  row=i//cols+1, \n",
    "                  col=i%cols+1, \n",
    "                  secondary_y=False,\n",
    "                  )\n",
    "     \n",
    "    fig.add_trace(go.Scatter(x=Ns, \n",
    "                             y=total_d[:, which_method, i],\n",
    "                             mode='lines+markers',\n",
    "                             line=go.scatter.Line(color=colors[2]),\n",
    "                             name = 'Total index',\n",
    "                             showlegend = showleg),\n",
    "                  row=i//cols+1, \n",
    "                  col=i%cols+1, \n",
    "                  secondary_y=False)\n",
    "\n",
    "    showleg = False\n",
    "    \n",
    "    \n",
    "fig.update_layout(width=990,\n",
    "                  height = 1100, \n",
    "                  legend_orientation=\"h\",\n",
    "                  legend=dict(x=0.67, y=1.1, font_size=16),\n",
    "                  title = methods_names[which_method].capitalize(),\n",
    "                 )\n",
    "\n",
    "max_y = max(max(first_d[:, which_method, :].flatten()), max(total_d[:, which_method, :].flatten()))\n",
    "min_y = min(min(first_d[:, which_method, :].flatten()), min(total_d[:, which_method, :].flatten()))\n",
    "\n",
    "# fig.update_yaxes(range=[min_y-0.5, max_y+0.5])\n",
    "fig.update_yaxes(range=[-0.5,0.5])\n",
    "# fig.update_xaxes(range=[155,200])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------THE END----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix zero total indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gsa_lca_dask import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, methods, gt_model, parameters = setup_gt_project(project, option)\n",
    "\n",
    "# 4. generate characterization matrices for all methods\n",
    "lca = bw.LCA(demand, methods[0])\n",
    "lca.lci(factorize=True)\n",
    "lca.lcia()\n",
    "lca.build_demand_array()\n",
    "method_matrices = gen_cf_matrices(lca, methods)\n",
    "\n",
    "gsa_in_lca = GSAinLCA(lca, parameters, gt_model, project = project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypardiso import spsolve\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lsa_scores(where, kind, lca, CF_mats):\n",
    "    \n",
    "    scores_dict = {}\n",
    "    \n",
    "    where_len = where.shape[0]\n",
    "    if where_len == 0:\n",
    "        return scores_dict\n",
    "    \n",
    "    N = 2\n",
    "    const_factor = (2-0.5)*np.random.random((where_len, N)) + 0.5\n",
    "    \n",
    "    if kind == 'tech':\n",
    "        rows = lca.tech_params[where]['row']\n",
    "        cols = lca.tech_params[where]['col']\n",
    "    elif kind == 'bio':\n",
    "        rows = lca.bio_params[where]['row']\n",
    "        cols = lca.bio_params[where]['col']\n",
    "    \n",
    "    for i in range(where_len):\n",
    "        \n",
    "        scores = np.zeros((len(CF_mats), N))\n",
    "        \n",
    "        for j in range(N):\n",
    "            A = deepcopy(lca.technosphere_matrix)\n",
    "            B = deepcopy(lca.biosphere_matrix)\n",
    "            x = deepcopy(spsolve(A, lca.demand_array))\n",
    "            \n",
    "            if kind == 'tech':\n",
    "                A[rows[i], cols[i]] *= const_factor[i,j]\n",
    "                x = spsolve(A, lca.demand_array)\n",
    "            elif kind == 'bio':\n",
    "                B[rows[i], cols[i]] *= const_factor[i,j]\n",
    "                \n",
    "            for k, CF_vec in enumerate(CF_mats):\n",
    "                scores[k,j] = CF_vec * B * x\n",
    "                \n",
    "            del A, B, x\n",
    "                \n",
    "        scores_dict[int(where[i])] = copy(scores)\n",
    "        \n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertain_exchanges_dict = gsa_in_lca.uncertain_exchanges_dict\n",
    "\n",
    "def local_sa(uncertain_exchanges_dict, lca): \n",
    "    \n",
    "    N = 2\n",
    "    B = lca.biosphere_matrix\n",
    "    lca.build_demand_array()\n",
    "    \n",
    "    CF_mats = []\n",
    "    for mat in method_matrices:\n",
    "        CF_mats.append(sum(mat))\n",
    "    \n",
    "    # 1. Technosphere\n",
    "    scores_dict_tech = compute_lsa_scores(uncertain_exchanges_dict['tech_params_where'], \n",
    "                                          'tech', \n",
    "                                          lca, \n",
    "                                          CF_mats)\n",
    "    # 2. Biosphere\n",
    "    scores_dict_bio  = compute_lsa_scores(uncertain_exchanges_dict['bio_params_where'], \n",
    "                                          'bio', \n",
    "                                          lca, \n",
    "                                          CF_mats)\n",
    "    \n",
    "    return scores_dict_tech, scores_dict_bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores_dict_tech, scores_dict_bio = local_sa(gsa_in_lca.parameterized_exchanges_dict, lca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'generated_files/gsa_results/cge_N560_LT_uniform.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    a = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range\n",
    "s1_cc = a['climate change total']['S1']\n",
    "s1_ce = a['carcinogenic effects']['S1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where([s1_cc[i] == 0 for i in range(len(s1_ce))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where([s1_ce[i] == 0 for i in range(len(s1_ce))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Y = dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobol indices\n",
    "model = dask.delayed(model)\n",
    "model_evals = []\n",
    "for sample in X:\n",
    "    model_eval = model(sample)\n",
    "    model_evals.append(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_batches = len(model_evals) // n_workers\n",
    "start = 0\n",
    "Y = [0]*n_batches\n",
    "for i_batch in range(n_batches):\n",
    "    end = (i_batch+1)*n_workers\n",
    "    Y[i_batch] = dask.compute(model_evals[start:end])\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.array(Y).flatten()\n",
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_sobol = sobol.analyze(problem, Y1, print_to_console=False, calc_second_order=calc_second_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_sobol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for all methods and store resutls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "# from dask.distributed import LocalCluster\n",
    "from dask_jobqueue import SLURMCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(cores     = 8, \n",
    "                       memory    ='4GB', \n",
    "                       walltime  = '02:00:00',\n",
    "                       interface ='ib0',\n",
    "                       local_directory = '/data/user/kim_a',\n",
    "                       log_directory   = '/data/user/kim_a')\n",
    "# if __name__ == '__main__':\n",
    "#     cluster = SLURMCluster(cores = 8, memory = '1GB')\n",
    "# cluster = LocalCluster(local_directory = '/data/user/kim_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 40\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "\n",
    "from gsa_lca_dask import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set current project\n",
    "project = 'Geothermal'\n",
    "bw.projects.set_current(project)\n",
    "\n",
    "#Local files\n",
    "from lookup_func import lookup_geothermal\n",
    "from cge_model import GeothermalConventionalModel\n",
    "from ege_model import GeothermalEnhancedModel\n",
    "\n",
    "#Choose demand/\n",
    "_, _, _, _, _, _, _, _, _, _, _, _, _, _, electricity_prod_conv, electricity_prod_enha = lookup_geothermal()\n",
    "\n",
    "#Choose LCIA method\n",
    "ILCD_CC = [method for method in bw.methods if \"ILCD 2.0 2018 midpoint no LT\" in str(method) and \"climate change total\" in str(method)]\n",
    "ILCD_HH = [method for method in bw.methods if \"ILCD 2.0 2018 midpoint no LT\" in str(method) and \"human health\" in str(method)]\n",
    "ILCD_EQ = [method for method in bw.methods if \"ILCD 2.0 2018 midpoint no LT\" in str(method) and \"ecosystem quality\" in str(method)]\n",
    "ILCD_RE = [method for method in bw.methods if \"ILCD 2.0 2018 midpoint no LT\" in str(method) and \"resources\" in str(method)]\n",
    "ILCD = ILCD_CC + ILCD_HH + ILCD_EQ + ILCD_RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'cge'\n",
    "if option == 'cge':\n",
    "    demand = {electricity_prod_conv: 1}\n",
    "    from cge_klausen import parameters\n",
    "    GTModel = GeothermalConventionalModel\n",
    "elif option == 'ege':\n",
    "    demand = {electricity_prod_enha: 1}\n",
    "    from ege_klausen import parameters\n",
    "    GTModel = GeothermalEnhancedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40\n",
    "\n",
    "n_dimensions = len(parameters.data)\n",
    "calc_second_order = False\n",
    "problem = {\n",
    "  'num_vars': n_dimensions,\n",
    "  'names':    np.arange(n_dimensions),\n",
    "  'bounds':   np.array([[0,1]]*n_dimensions)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. dask.delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "calc_second_order = False\n",
    "X = saltelli.sample(problem, N, calc_second_order=calc_second_order)\n",
    "\n",
    "def get_model_evals(model, X):\n",
    "    model_evals = []\n",
    "    for sample in X:\n",
    "        model_eval = model(sample)\n",
    "        model_evals.append(model_eval)        \n",
    "    return model_evals\n",
    "\n",
    "\n",
    "def get_Y(model_evals):\n",
    "    n_batches = len(model_evals) // n_workers\n",
    "    start = 0\n",
    "    Y = [0]*n_batches\n",
    "    for i_batch in range(n_batches):\n",
    "        end = (i_batch+1)*n_workers\n",
    "        Y[i_batch] = dask.compute(model_evals[start:end])\n",
    "        start = end\n",
    "    return Y\n",
    "        \n",
    "\n",
    "def sobol_wrt_method(demand, method, option):\n",
    "\n",
    "    lca = bw.LCA(demand, method)\n",
    "    lca.lci()\n",
    "    lca.lcia()\n",
    "    lca.build_demand_array()\n",
    "\n",
    "    print(method)\n",
    "\n",
    "    def model(sample):\n",
    "        if option == 'cge':\n",
    "            from cge_klausen import parameters\n",
    "            GTModel = GeothermalConventionalModel\n",
    "        elif option == 'ege':\n",
    "            from cge_klausen import parameters\n",
    "            GTModel = GeothermalEnhancedModel\n",
    "        lca_ = copy(lca)\n",
    "        gt_model = GTModel(parameters)\n",
    "        gsa_in_lca = GSAinLCA(project, demand, method, parameters, gt_model, lca_)\n",
    "        return gsa_in_lca.model(sample)\n",
    "    \n",
    "    model = dask.delayed(model)\n",
    "    \n",
    "    model_evals = get_model_evals(model, X)\n",
    "    Y = get_Y(model_evals)\n",
    "    Y = np.array(Y).flatten()\n",
    "    sa_sobol = sobol.analyze(problem, Y, print_to_console=False, calc_second_order=calc_second_order)\n",
    "    \n",
    "    return sa_sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_sobol = {}\n",
    "path = \"/psi/home/kim_a/geothermal/write_files\" + '_' + option\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save names of parameters\n",
    "method = ILCD[0]\n",
    "lca = bw.LCA(demand, method)\n",
    "lca.lci()\n",
    "lca.lcia()\n",
    "    \n",
    "path_n = os.path.join(path, 'parameters.json')\n",
    "gt_model = GTModel(parameters)\n",
    "gsa_in_lca = GSAinLCA(project, demand, method, parameters, gt_model, lca)\n",
    "\n",
    "with open(path_n, 'w') as f:\n",
    "    json.dump(gsa_in_lca.parameters_array['name'].tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for method in ILCD:\n",
    "    method_name = method[-1]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    sa_dict = sobol_wrt_method(demand, method, option)\n",
    "    t1 = time.time()\n",
    "    print('Time needed for this method: ' + str(t1-t0))\n",
    "    \n",
    "    sa_sobol[method_name] = sa_dict\n",
    "    \n",
    "    # Save\n",
    "    for k,v in sa_dict.items():\n",
    "        sa_dict[k] = v.tolist()\n",
    "    path_m = os.path.join(path, method[-1].replace(' ', '_') + '.json')\n",
    "    with open(path_m, 'w') as f:\n",
    "        json.dump(sa_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random(2077)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_lca_dask import GSAinLCA\n",
    "from cge_klausen import parameters\n",
    "from cge_model import GeothermalConventionalModel\n",
    "from lookup_func import lookup_geothermal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.projects.set_current('Geothermal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsa_lca_dask import GSAinLCA\n",
    "from cge_klausen import parameters\n",
    "from cge_model import GeothermalConventionalModel\n",
    "from lookup_func import lookup_geothermal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, _, _, _, _, _, _, _, _, _, _, electricity_prod_conv, electricity_prod_enha = lookup_geothermal()\n",
    "demand = {electricity_prod_conv: 1}\n",
    "method = [method for method in bw.methods if \"ILCD 2.0 2018 midpoint no LT\" in str(method) \n",
    "          and \"climate change total\" in str(method)][0]\n",
    "lca = bw.LCA(demand, method)\n",
    "lca.lci()\n",
    "lca.lcia()\n",
    "print(lca.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
