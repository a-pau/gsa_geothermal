{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create bw project and set it to current "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Geothermal'  \n",
    "bw.projects.set_current(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 3 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.6 cutoff\n",
       "\tgeothermal energy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import biosphere and ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biosphere database already present!!! No setup is needed\n"
     ]
    }
   ],
   "source": [
    "bw.bw2setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoinvent 3.6 cutoff database already present!!! No import is needed\n"
     ]
    }
   ],
   "source": [
    "ei_name = \"ecoinvent 3.6 cutoff\"    \n",
    "# ei_path = \"/psi/home/kim_a/LCA files/ecoinvent 3.5 cutoff/datasets\"\n",
    "ei_path = \"/Users/akim/Documents/LCA files/ecoinvent 3.6 cutoff/datasets\"\n",
    "if ei_name in bw.databases:\n",
    "    print(ei_name + \" database already present!!! No import is needed\")\n",
    "else:\n",
    "    ei = bw.SingleOutputEcospold2Importer(ei_path, ei_name)\n",
    "    ei.apply_strategies()\n",
    "    ei.statistics()\n",
    "    ei.write_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import `geothermal energy` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 3 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.6 cutoff\n",
       "\tgeothermal energy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Import_and_Replace.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start DASK Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_comp = 'merlin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option_comp == \"merlin\":\n",
    "\n",
    "    from dask_jobqueue import SLURMCluster\n",
    "    \n",
    "    cluster = SLURMCluster(cores     = 4, \n",
    "                           memory    ='4GB', \n",
    "                           walltime  = '10:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = '/data/user/kim_a',\n",
    "                           log_directory   = '/data/user/kim_a',\n",
    "                          ) \n",
    "    \n",
    "elif option_comp == \"local\":\n",
    "    \n",
    "    from dask.distributed import LocalCluster\n",
    "    \n",
    "    cluster = LocalCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 3\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://192.168.196.28:34049</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.196.28:8787/status' target='_blank'>http://192.168.196.28:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>12.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.196.28:34049' processes=3 threads=12, memory=12.00 GB>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import brightway2 as bw\n",
    "from copy import copy\n",
    "\n",
    "from utils.gsa_lca_dask import *\n",
    "from setup_files_gsa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose option: EGE or CGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'cge'\n",
    "diff_distr = False # set to true when checking for robustness of GSA results to distribution choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose number of Monte Carlo runs for one total index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create long task for each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices):\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for sample in X_chunk:\n",
    "        score = gsa_in_lca.model(sample, method_matrices)\n",
    "        scores.append(score)\n",
    "        i += 1\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_per_worker(project, N, option, n_workers, i_chunk, path_files, diff_distr):\n",
    "\n",
    "    # 1. setup geothermal project\n",
    "    demand, gt_model, parameters = setup_gt_project(project, option, diff_distr=diff_distr)\n",
    "    methods = get_ILCD_methods(CC_only=False, units=False)\n",
    "    \n",
    "    # 2. generate characterization matrices for all methods\n",
    "    lca = bw.LCA(demand, methods[0])\n",
    "    lca.lci(factorize=True)\n",
    "    lca.lcia()\n",
    "    lca.build_demand_array()\n",
    "    method_matrices = gen_cf_matrices(lca, methods)\n",
    "\n",
    "    # 3. gsa in lca model\n",
    "    gsa_in_lca = GSAinLCA(lca, parameters, gt_model, project=project)\n",
    "\n",
    "    # 4. setup GSA project in the SALib format\n",
    "    num_vars = len(gsa_in_lca.parameters_array) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['tech_params_where']) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['bio_params_where'])\n",
    "    problem, calc_second_order = setup_gsa(num_vars)\n",
    "\n",
    "    # 5. generate sobol samples, choose correct chunk for the current worker based on index i_chunk\n",
    "    X = saltelli.sample(problem, N, calc_second_order=calc_second_order)\n",
    "\n",
    "    # 6. Extract part of the sample for the current worker\n",
    "    chunk_size = X.shape[0]//n_workers\n",
    "    start = i_chunk*chunk_size\n",
    "    if i_chunk != n_workers-1:\n",
    "        end = (i_chunk+1)*chunk_size\n",
    "    else:\n",
    "        end = X.shape[0] \n",
    "    X_chunk = X[start:end, :]\n",
    "    del X\n",
    "\n",
    "    # 6. compute scores for all methods for X_chunk  \n",
    "    scores_for_methods = model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices)\n",
    "    \n",
    "    # 7. Save results\n",
    "    filepath = os.path.join(path_files, 'scores_' + str(start) + '_' + str(end-1) + '.pkl')\n",
    "    with open(filepath, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores_for_methods, fp)\n",
    "\n",
    "    return scores_for_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for saving results\n",
    "path = \"generated_files/write_files\"\n",
    "path_files = os.path.join(path, option + '_N' + str(N))\n",
    "if not os.path.exists(path_files):\n",
    "    os.makedirs(path_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 37s, sys: 2.58 s, total: 2min 39s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i_chunk = 0\n",
    "N = 2\n",
    "n_workers = 2\n",
    "scores_for_methods = task_per_worker(project, N, option, n_workers, i_chunk, path_files, diff_distr=diff_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_per_worker = dask.delayed(task_per_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals = []\n",
    "for i in range(n_workers):\n",
    "    model_eval = task_per_worker(project, N, option, n_workers, i, path_files, diff_distr=diff_distr)\n",
    "    model_evals.append(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 12.8 s, total: 1min 34s\n",
      "Wall time: 45min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_intermediate = dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing of model outputs Y and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_intermediate = np.array(Y_intermediate).squeeze()\n",
    "Y_all_methods = np.vstack(Y_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140, 16)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all_methods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(path_files, 'all_scores.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(Y_all_methods, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bw]",
   "language": "python",
   "name": "conda-env-bw-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
