{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create bw project and set it to current "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Geothermal'  \n",
    "bw.projects.set_current(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 3 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.6 cutoff\n",
       "\tgeothermal energy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import biosphere and ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biosphere database already present!!! No setup is needed\n"
     ]
    }
   ],
   "source": [
    "bw.bw2setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecoinvent 3.6 cutoff database already present!!! No import is needed\n"
     ]
    }
   ],
   "source": [
    "ei_name = \"ecoinvent 3.6 cutoff\"    \n",
    "# ei_path = \"/psi/home/kim_a/LCA files/ecoinvent 3.5 cutoff/datasets\"\n",
    "ei_path = \"/Users/akim/Documents/LCA files/ecoinvent 3.6 cutoff/datasets\"\n",
    "if ei_name in bw.databases:\n",
    "    print(ei_name + \" database already present!!! No import is needed\")\n",
    "else:\n",
    "    ei = bw.SingleOutputEcospold2Importer(ei_path, ei_name)\n",
    "    ei.apply_strategies()\n",
    "    ei.statistics()\n",
    "    ei.write_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import `geothermal energy` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 3 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.6 cutoff\n",
       "\tgeothermal energy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database already exists\n",
      "Do you want to delete it and reimport? Y/N? N\n",
      "Skipping import\n"
     ]
    }
   ],
   "source": [
    "%run Import_and_Replace.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start DASK Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_comp = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option_comp == \"merlin\":\n",
    "\n",
    "    from dask_jobqueue import SLURMCluster\n",
    "    \n",
    "    cluster = SLURMCluster(cores     = 8, \n",
    "                           memory    ='4GB', \n",
    "                           walltime  = '10:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = '/data/user/kim_a',\n",
    "                           log_directory   = '/data/user/kim_a',\n",
    "                          ) \n",
    "    \n",
    "elif option_comp == \"local\":\n",
    "    \n",
    "    from dask.distributed import LocalCluster\n",
    "    \n",
    "    cluster = LocalCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 10\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:59421</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>10</li>\n",
       "  <li><b>Cores: </b>30</li>\n",
       "  <li><b>Memory: </b>42.95 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:59421' processes=10 threads=30, memory=42.95 GB>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()\n",
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import brightway2 as bw\n",
    "from copy import copy\n",
    "\n",
    "from utils.gsa_lca_dask import *\n",
    "from setup_files_gsa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose option: EGE or CGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'cge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose number of Monte Carlo runs for one total index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create long task for each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices):\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for sample in X_chunk:\n",
    "        score = gsa_in_lca.model(sample, method_matrices)\n",
    "        scores.append(score)\n",
    "        i += 1\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_per_worker(project, N, option, n_workers, i_chunk, path_files, diff_distr):\n",
    "\n",
    "    # 1. setup geothermal project\n",
    "    demand, gt_model, parameters = setup_gt_project(project, option, diff_distr=diff_distr)\n",
    "    methods = get_ILCD_methods(CC_only=False, units=False)\n",
    "    \n",
    "    # 2. generate characterization matrices for all methods\n",
    "    lca = bw.LCA(demand, methods[0])\n",
    "    lca.lci(factorize=True)\n",
    "    lca.lcia()\n",
    "    lca.build_demand_array()\n",
    "    method_matrices = gen_cf_matrices(lca, methods)\n",
    "\n",
    "    # 3. gsa in lca model\n",
    "    gsa_in_lca = GSAinLCA(lca, parameters, gt_model, project=project)\n",
    "\n",
    "    # 4. setup GSA project in the SALib format\n",
    "    num_vars = len(gsa_in_lca.parameters_array) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['tech_params_where']) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['bio_params_where'])\n",
    "    problem, calc_second_order = setup_gsa(num_vars)\n",
    "\n",
    "    # 5. generate sobol samples, choose correct chunk for the current worker based on index i_chunk\n",
    "    X = saltelli.sample(problem, N, calc_second_order=calc_second_order)\n",
    "\n",
    "    # 6. Extract part of the sample for the current worker\n",
    "    chunk_size = X.shape[0]//n_workers\n",
    "    start = i_chunk*chunk_size\n",
    "    if i_chunk != n_workers-1:\n",
    "        end = (i_chunk+1)*chunk_size\n",
    "    else:\n",
    "        end = X.shape[0] \n",
    "    X_chunk = X[start:end, :]\n",
    "    del X\n",
    "\n",
    "    # 6. compute scores for all methods for X_chunk  \n",
    "    scores_for_methods = model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices)\n",
    "    \n",
    "    # 7. Save results\n",
    "    filepath = os.path.join(path_files, 'scores_' + str(start) + '_' + str(end-1) + '.pkl')\n",
    "    with open(filepath, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores_for_methods, fp)\n",
    "\n",
    "    return scores_for_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for saving results\n",
    "path = \"generated_files/write_files\"\n",
    "path_files = os.path.join(path, option + '_N' + str(N))\n",
    "if not os.path.exists(path_files):\n",
    "    os.makedirs(path_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i_chunk = 0\n",
    "# scores_for_methods = task_per_worker(project, N, option, n_workers, i_chunk, path_files, diff_distr=diff_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_per_worker = dask.delayed(task_per_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals = []\n",
    "for i in range(n_workers):\n",
    "    model_eval = task_per_worker(project, N, option, n_workers, i, path_files)\n",
    "    model_evals.append(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 18s, sys: 2min 4s, total: 15min 23s\n",
      "Wall time: 3h 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_intermediate = dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing of model outputs Y and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_intermediate = np.array(Y_intermediate).squeeze()\n",
    "Y_all_methods = np.vstack(Y_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500, 16)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all_methods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(path_files, 'all_scores.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(Y_all_methods, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
