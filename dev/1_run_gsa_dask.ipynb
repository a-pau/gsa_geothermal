{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create bw project and set it to current "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 3 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.6 cutoff\n",
       "\tgeothermal energy"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bw2data as bd\n",
    "project = 'Geothermal'  \n",
    "bd.projects.set_current(project)\n",
    "bd.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start DASK Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_comp = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if option_comp == \"merlin\":\n",
    "\n",
    "    from dask_jobqueue import SLURMCluster\n",
    "    \n",
    "    cluster = SLURMCluster(cores     = 4, \n",
    "                           memory    ='4GB', \n",
    "                           walltime  = '10:00:00',\n",
    "                           interface ='ib0',\n",
    "                           local_directory = '/data/user/kim_a',\n",
    "                           log_directory   = '/data/user/kim_a',\n",
    "                          ) \n",
    "    \n",
    "elif option_comp == \"local\":\n",
    "    \n",
    "    from dask.distributed import LocalCluster\n",
    "    \n",
    "    cluster = LocalCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = 25\n",
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import copy\n",
    "\n",
    "# from utils.gsa_lca_dask import *\n",
    "# from setup_files_gsa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose option: EGE or CGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = 'cge'\n",
    "diff_distr = True # set to true when checking for robustness of GSA results to distribution choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> TODO choose number of Monte Carlo runs for one total index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create long task for each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices):\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for sample in X_chunk:\n",
    "        score = gsa_in_lca.model(sample, method_matrices)\n",
    "        scores.append(score)\n",
    "        i += 1\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_per_worker(project, N, option, n_workers, i_chunk, path_files, diff_distr):\n",
    "\n",
    "    # 1. setup geothermal project\n",
    "    demand, gt_model, parameters = setup_gt_project(project, option, diff_distr=diff_distr)\n",
    "    methods = get_ILCD_methods(CC_only=False, units=False)\n",
    "    \n",
    "    # 2. generate characterization matrices for all methods\n",
    "    lca = bw.LCA(demand, methods[0])\n",
    "    lca.lci(factorize=True)\n",
    "    lca.lcia()\n",
    "    lca.build_demand_array()\n",
    "    method_matrices = gen_cf_matrices(lca, methods)\n",
    "\n",
    "    # 3. gsa in lca model\n",
    "    gsa_in_lca = GSAinLCA(lca, parameters, gt_model, project=project)\n",
    "\n",
    "    # 4. setup GSA project in the SALib format\n",
    "    num_vars = len(gsa_in_lca.parameters_array) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['tech_params_where']) \\\n",
    "             + len(gsa_in_lca.uncertain_exchanges_dict['bio_params_where'])\n",
    "    problem, calc_second_order = setup_gsa(num_vars)\n",
    "\n",
    "    # 5. generate sobol samples, choose correct chunk for the current worker based on index i_chunk\n",
    "    X = saltelli.sample(problem, N, calc_second_order=calc_second_order)\n",
    "\n",
    "    # 6. Extract part of the sample for the current worker\n",
    "    chunk_size = X.shape[0]//n_workers\n",
    "    start = i_chunk*chunk_size\n",
    "    if i_chunk != n_workers-1:\n",
    "        end = (i_chunk+1)*chunk_size\n",
    "    else:\n",
    "        end = X.shape[0] \n",
    "    X_chunk = X[start:end, :]\n",
    "    del X\n",
    "\n",
    "    # 6. compute scores for all methods for X_chunk  \n",
    "    scores_for_methods = model_per_X_chunk(X_chunk, gsa_in_lca, method_matrices)\n",
    "    \n",
    "    # 7. Save results\n",
    "    filepath = os.path.join(path_files, 'scores_' + str(start) + '_' + str(end-1) + '.pkl')\n",
    "    with open(filepath, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(scores_for_methods, fp)\n",
    "\n",
    "    return scores_for_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for saving results\n",
    "write_dir = Path(\"write_files\")\n",
    "write_dir\n",
    "if diff_distr == False:\n",
    "    path_files = os.path.join(path, option + '_N' + str(N))\n",
    "elif diff_distr == True:\n",
    "    path_files = os.path.join(path, option + '_N' + str(N) + '_robust')\n",
    "if not os.path.exists(path_files):\n",
    "    os.makedirs(path_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i_chunk = 0\n",
    "# N = 1\n",
    "# n_workers = 1\n",
    "# scores_for_methods = task_per_worker(project, N, option, n_workers, i_chunk, path_files, diff_distr=diff_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_per_worker = dask.delayed(task_per_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals = []\n",
    "for i in range(n_workers):\n",
    "    model_eval = task_per_worker(project, N, option, n_workers, i, path_files, diff_distr=diff_distr)\n",
    "    model_evals.append(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Y_intermediate = dask.compute(model_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing of model outputs Y and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_intermediate = np.array(Y_intermediate).squeeze()\n",
    "Y_all_methods = np.vstack(Y_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all_methods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(path_files, 'all_scores.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(Y_all_methods, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
